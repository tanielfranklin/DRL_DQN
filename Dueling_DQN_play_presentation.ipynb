{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dueling DQN with prioritized replay in  Robot Toolbox for Python and Swift.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "from IPython.display import clear_output\n",
    "from scipy.signal import convolve, gaussian\n",
    "import os\n",
    "import io\n",
    "import base64\n",
    "import time\n",
    "import glob\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "import data_panda as rbt\n",
    "device = 'cpu'\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#j3 range -0.08 a 3.75  #j2 range -0.07 a -3. #j1 range -1.8 a 1.76"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robot and enviroment\n",
    "\n",
    "Panda robot and obstacle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    Observation:\n",
    "        Type: Box(4)\n",
    "        Num     Observation               Min                     Max\n",
    "\n",
    "        0       Joint1                   -4.8                    4.8\n",
    "        1       Joint2                    -Inf                    Inf\n",
    "        2       Joint3                -0.418 rad (-24 deg)    0.418 rad (24 deg)\n",
    "        \n",
    "    Actions:\n",
    "        Type: Discrete 3^3 27 actions\n",
    "        \n",
    "        Num   Three actions for each joint\n",
    "         0     do n joint j\n",
    "         1     increment angle of joint j\n",
    "        -1     decrement angle of joint j\n",
    "\n",
    "        #j3 range 0.0 a 3.7\n",
    "        #j2 range 0.0 a -3.\n",
    "        #j1 range -1.7 a 1.7\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_shape = 3\n",
    "env=rbt.Panda_RL()\n",
    "config = rbt.load_config(\"config_dueling.yaml\")\n",
    "agent=rbt.DuelingDQNAgent(state_shape, device,layers=config[\"dueling_layers\"], epsilon=0)\n",
    "env.renderize=True #start/stop robot viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERobot: panda (by Franka Emika), 7 joints (RRRRRRR), 1 gripper, geometry, collision\n",
       "┌─────┬──────────────┬───────┬─────────────┬────────────────────────────────────────────────┐\n",
       "│link │     link     │ joint │   parent    │              ETS: parent to link               │\n",
       "├─────┼──────────────┼───────┼─────────────┼────────────────────────────────────────────────┤\n",
       "│   0 │ panda_link0  │       │ BASE        │                                                │\n",
       "│   1 │ panda_link1  │     0 │ panda_link0 │ SE3(0, 0, 0.333) ⊕ Rz(q0)                      │\n",
       "│   2 │ panda_link2  │     1 │ panda_link1 │ SE3(-90°, -0°, 0°) ⊕ Rz(q1)                    │\n",
       "│   3 │ panda_link3  │     2 │ panda_link2 │ SE3(0, -0.316, 0; 90°, -0°, 0°) ⊕ Rz(q2)       │\n",
       "│   4 │ panda_link4  │     3 │ panda_link3 │ SE3(0.0825, 0, 0; 90°, -0°, 0°) ⊕ Rz(q3)       │\n",
       "│   5 │ panda_link5  │     4 │ panda_link4 │ SE3(-0.0825, 0.384, 0; -90°, -0°, 0°) ⊕ Rz(q4) │\n",
       "│   6 │ panda_link6  │     5 │ panda_link5 │ SE3(90°, -0°, 0°) ⊕ Rz(q5)                     │\n",
       "│   7 │ panda_link7  │     6 │ panda_link6 │ SE3(0.088, 0, 0; 90°, -0°, 0°) ⊕ Rz(q6)        │\n",
       "│   8 │ @panda_link8 │       │ panda_link7 │ SE3(0, 0, 0.107)                               │\n",
       "└─────┴──────────────┴───────┴─────────────┴────────────────────────────────────────────────┘\n",
       "\n",
       "┌─────┬─────┬────────┬─────┬───────┬─────┬───────┬──────┐\n",
       "│name │ q0  │ q1     │ q2  │ q3    │ q4  │ q5    │ q6   │\n",
       "├─────┼─────┼────────┼─────┼───────┼─────┼───────┼──────┤\n",
       "│  qr │  0° │ -17.2° │  0° │ -126° │  0° │  115° │  45° │\n",
       "│  qz │  0° │  0°    │  0° │  0°   │  0° │  0°   │  0°  │\n",
       "└─────┴─────┴────────┴─────┴───────┴─────┴───────┴──────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.panda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main loop\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intializing with a given state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.start_scene()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_far=np.array([ 0., -0.8 ,  0. , -0.0698,  0.,  3.3825,  0.    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taniel/mambaforge/envs/RTP/lib/python3.10/site-packages/roboticstoolbox/robot/Link.py:1041: FutureWarning: base kwarg is deprecated, use pose instead\n",
      "  warn(\"base kwarg is deprecated, use pose instead\", FutureWarning)\n",
      "pybullet build time: Oct 28 2022 16:11:27\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(660.2687703402628, 99.0, 0.0, 0.0, 1.8795566196116154, [['Running', '']])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbt.evaluate(env, agent, n_games=1, greedy=False, t_max=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.6 , -2.6 ,  0.71])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# env.reset_j1=[-1.7,1.7]\n",
    "# env.reset_j1=[-1.7,-1.]\n",
    "\n",
    "\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1.6 , -2.61,  0.72]), -20.668002602340454, False, ['Running', ''])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.array([0,-1,1])\n",
    "\n",
    "env.step(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 0.35, -0.84,  3.7 ]), 10.689578002188107, False, ['Running', ''])\n",
      "0.010005201172680325\n",
      "(array([ 0.35, -0.84,  3.69]), 100, True, ['Done', 'Completed'])\n",
      "2.1073424255447017e-08\n"
     ]
    }
   ],
   "source": [
    "env.panda.q=env.q_goal\n",
    "print(env.step([0,0,1]))\n",
    "print(sum(env.fitness()))\n",
    "print(env.step([0,0,-1]))\n",
    "print(sum(env.fitness()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score:2937.821683087388 in 600 steps, minimum distance 0.0020300392991623234\n",
      "Status: Running \n"
     ]
    }
   ],
   "source": [
    "folder=\"new_2\"\n",
    "#env.reset_j1=[-1.7,-1.]\n",
    "agent.play(env,folder,tmax=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score:2775.5891783840175 in 300 steps, minimum distance 0.03384482789943642\n",
      "Status: Running \n"
     ]
    }
   ],
   "source": [
    "agent.play(env,folder,tmax=300,model=\"other\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score:1579.0398777921607 in 263 steps, minimum distance 1.1552150760724987e-05\n",
      "Status: Done Completed\n"
     ]
    }
   ],
   "source": [
    "folder=\"obs_10_12_13\"\n",
    "#env.reset_j1=[-1.7,-1.]\n",
    "agent.play(env,folder,tmax=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score:1538.8585640526774 in 272 steps, minimum distance 0.0017304747049568894\n",
      "Status: Done Completed\n"
     ]
    }
   ],
   "source": [
    "agent.play(env,folder,tmax=400,model=\"other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(agent.state_dict(), \"model_ok_2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score:1556.115741654673 in 274 steps, minimum distance 0.0020009016994586766\n",
      "Status: Done Completed\n"
     ]
    }
   ],
   "source": [
    "agent.play(env,folder,tmax=400,model=\"last\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activate Ceil obstacle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.ceil=True\n",
    "env.close_scene()\n",
    "env.start_scene()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let us record a video of trained agent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Animate learned policy\n",
    "# save_dir='./videos/'\n",
    "# #env = make_env(env_name)\n",
    "# generate_animation(env, agent, save_dir=save_dir)\n",
    "# [filepath] = glob.glob(os.path.join(save_dir, '*.mp4'))\n",
    "\n",
    "# display_animation(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "\n",
    "# Run this on another environment in OpenAI Gym\n",
    "# Create a robotic environment with more actions\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('RTP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "a1c32bf4b5685cea35b7222c9dc34db2c6da643e20138226fc292aae96f14cc5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
